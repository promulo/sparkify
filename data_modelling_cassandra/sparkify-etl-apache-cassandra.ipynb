{
 "cells": [
  {
   "source": [
    "# Part I: ETL pipeline for processing of the CSV data files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the ETL process is to compile a list of all the raw CSV files inside the `event_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path.cwd() / 'event_data'\n",
    "for root, _, _ in os.walk(dataset_path):    \n",
    "    dataset_files = sorted(Path(root).glob('*.csv'))"
   ]
  },
  {
   "source": [
    "The next step is to process the above listed files in order to create the single CSV that will later be used to populate the Apache Casssandra tables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_CSV_FILE = 'event_datafile_new.csv'\n",
    "\n",
    "full_data_rows_list = []\n",
    "for f in dataset_files:\n",
    "    with open(f, 'r', encoding='utf8', newline='') as csv_file: \n",
    "        csv_reader = csv.reader(csv_file)         \n",
    "        next(csv_reader) # skips CSV header line\n",
    "        for line in csv_reader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "csv.register_dialect('events', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "# here we join all valid rows from the separate CSVs into one single CSV file\n",
    "with open(DATA_CSV_FILE, 'w', encoding='utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='events')\n",
    "    writer.writerow([\n",
    "        'artist',\n",
    "        'firstName',\n",
    "        'gender',\n",
    "        'itemInSession',\n",
    "        'lastName',\n",
    "        'length',\n",
    "        'level',\n",
    "        'location',\n",
    "        'sessionId',\n",
    "        'song',\n",
    "        'userId'\n",
    "    ])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] != ''):\n",
    "            writer.writerow((\n",
    "                row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_CSV_FILE, 'r', encoding='utf8') as f:\n",
    "    print(\"Number of rows on 'event_datafile_new.csv': {}\".format(sum(1 for line in f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Data modelling using Apache Cassandra\n",
    "At this point, all CSV files from the `event_data` directory were processed and joined into a single CSV data file named `event_datafile_new.csv`. That file contains the following columns (the meaning of each one is detailed in parenthesis):\n",
    "- `artist` (artist name)\n",
    "- `firstName` (user first name)\n",
    "- `gender` (user gender)\n",
    "- `itemInSession` (session item number)\n",
    "- `lastName` (user last name)\n",
    "- `length` (song length)\n",
    "- `level` (user level, i.e. free or paid plan)\n",
    "- `location` (user location)\n",
    "- `sessionId` (session ID)\n",
    "- `song` (song title)\n",
    "- `userId` (user ID)\n",
    "\n",
    "The image below is a screenshot of what the data should look like in after the CSV processing code is executed:\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_keyspace_query = \"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "    WITH REPLICATION = { \n",
    "        'class': 'SimpleStrategy', \n",
    "        'replication_factor': 1 \n",
    "    };\n",
    "\"\"\"\n",
    "session.execute(create_keyspace_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('sparkify')\n"
   ]
  },
  {
   "source": [
    "## Data model and queries\n",
    "In the context of Sparkify's songplay events database, here are some of the questions that must be answered by our data model:\n",
    "\n",
    "1. Which were the **artist name**, **song title and length** listened during the **session** with **ID 338** and **session item** number **4**?\n",
    "2. What is the **full name of the user**, the **artist** and **song** (sorted by **session item** number) listened by the **user** with **ID 10** during the **session** with **ID 182**?\n",
    "3. What is the **full name of all the users** who listened to the **song** named '**All Hands Against His Own**'?\n",
    "\n",
    "All tables were designed with the above questions in mind. The code that creates those tables in Apache Cassandra can be seen in the following cells.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_songplays_by_session = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songplay_events_by_session (\n",
    "    session_id INT,\n",
    "    session_item INT,\n",
    "    artist_name TEXT,\n",
    "    song_title TEXT,\n",
    "    song_length FLOAT,\n",
    "    PRIMARY KEY ((session_id), session_item)\n",
    ");\n",
    "\"\"\"\n",
    "session.execute(create_table_songplays_by_session)\n",
    "\n",
    "create_table_songplays_by_user = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songplay_events_by_user (\n",
    "    user_id INT,\n",
    "    session_id INT,\n",
    "    session_item INT,\n",
    "    artist_name TEXT,\n",
    "    song_title TEXT,\n",
    "    user_full_name TEXT,\n",
    "    PRIMARY KEY ((user_id), session_id, session_item)\n",
    ");\n",
    "\"\"\"\n",
    "session.execute(create_table_songplays_by_user)\n",
    "\n",
    "create_table_songplays_by_song = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songplay_events_by_song (\n",
    "    song_title TEXT,\n",
    "    user_id INT,\n",
    "    user_full_name TEXT,\n",
    "    PRIMARY KEY ((song_title), user_id)\n",
    ");\n",
    "\"\"\"\n",
    "session.execute(create_table_songplays_by_song)"
   ]
  },
  {
   "source": [
    "With the tables created, the data previously compiled in the `event_datafile_new.csv` file can be used to populate them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "INSERT INTO songplay_events_by_session (\n",
    "    session_id, \n",
    "    session_item, \n",
    "    artist_name, \n",
    "    song_title, \n",
    "    song_length\n",
    ")\n",
    "VALUES (?, ?, ?, ?, ?);\n",
    "\"\"\"\n",
    "insert_stmt_songplays_by_session = session.prepare(insert_query)\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO {} (\n",
    "    user_id,\n",
    "    session_id, \n",
    "    session_item, \n",
    "    artist_name, \n",
    "    song_title, \n",
    "    user_full_name\n",
    ")\n",
    "VALUES (?, ?, ?, ?, ?, ?);\n",
    "\"\"\"\n",
    "insert_stmt_songplays_by_user = session.prepare(insert_query.format('songplay_events_by_user'))\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO {} (\n",
    "    song_title, \n",
    "    user_id, \n",
    "    user_full_name\n",
    ")\n",
    "VALUES (?, ?, ?);\n",
    "\"\"\"\n",
    "insert_stmt_songplays_by_song = session.prepare(insert_query.format('songplay_events_by_song'))\n",
    "\n",
    "with open(DATA_CSV_FILE, encoding='utf8') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    next(csv_reader) # skips CSV header line\n",
    "    for line in csv_reader:\n",
    "        row = [\n",
    "            int(line[8]),   # session_id\n",
    "            int(line[3]),   # session_item\n",
    "            line[0],        # artist_name\n",
    "            line[9],        # song_title\n",
    "            float(line[5]), # song_length\n",
    "        ]\n",
    "        session.execute(insert_stmt_songplays_by_session, row)\n",
    "        \n",
    "        user_full_name = '{} {}'.format(line[1].strip(), line[4].strip())\n",
    "\n",
    "        row = [\n",
    "            int(line[10]),  # user_id\n",
    "            int(line[8]),   # session_id\n",
    "            int(line[3]),   # session_item\n",
    "            line[0],        # artist_name\n",
    "            line[9],        # song_title\n",
    "            user_full_name, # user_full_name\n",
    "        ]\n",
    "        session.execute(insert_stmt_songplays_by_user, row)\n",
    "\n",
    "        row = [\n",
    "            line[9],        # song_title\n",
    "            int(line[10]),  # user_id\n",
    "            user_full_name, # user_full_name\n",
    "        ]\n",
    "        session.execute(insert_stmt_songplays_by_song, row)"
   ]
  },
  {
   "source": [
    "The following cells translate the questions to be answered by the data into Cassandra CQL queries. The numbering on the variables maps to the number given to the example questions above (i.e. `query_01` below relates to the question 1 defined and so on)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Which were the artist name, song title and song length heard during \n",
    "#    the session with ID 338 and session item number 4?\n",
    "query_01 = \"\"\"\n",
    "SELECT artist_name, song_title, song_length\n",
    "FROM songplay_events_by_session\n",
    "WHERE session_id = ? AND session_item = ?;\n",
    "\"\"\"\n",
    "query_01_stmt = session.prepare(query_01)\n",
    "result = session.execute(query_01_stmt, [338, 4])\n",
    "row = result.one()\n",
    "print('artist: {}\\nsong: {}\\nlength: {:.2f}\\n'.format(row.artist_name, row.song_title, row.song_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the full name of the user, the artist and song (sorted by session item number) \n",
    "#    listened by the user with ID 10 during the session with ID 182?\n",
    "query_02 = \"\"\"\n",
    "SELECT artist_name, song_title, user_full_name\n",
    "FROM songplay_events_by_user\n",
    "WHERE user_id = ? AND session_id = ?;\n",
    "\"\"\"\n",
    "query_02_stmt = session.prepare(query_02)\n",
    "result = session.execute(query_02_stmt, [10, 182])\n",
    "rows = result.all()\n",
    "for row in rows:\n",
    "    print('artist: {}\\nsong: {}\\nuser: {}\\n'.format(row.artist_name, row.song_title, row.user_full_name))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the full name of all the users who listened to the song named 'All Hands Against His Own'?\n",
    "query_03 = \"\"\"\n",
    "SELECT user_full_name \n",
    "FROM songplay_events_by_song\n",
    "WHERE song_title = ?;\n",
    "\"\"\"\n",
    "query_03_stmt = session.prepare(query_03)\n",
    "result = session.execute(query_03_stmt, ['All Hands Against His Own'])\n",
    "rows = result.all()\n",
    "for row in rows:\n",
    "    print('{}\\n'.format(row.user_full_name)) "
   ]
  },
  {
   "source": [
    "After the ETL process and database querying is complete, the tables can be dropped from Cassandra."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_stmt = [\n",
    "    'DROP TABLE IF EXISTS songplay_events_by_session;',    \n",
    "    'DROP TABLE IF EXISTS songplay_events_by_song;',\n",
    "    'DROP TABLE IF EXISTS songplay_events_by_user;',\n",
    "    'DROP KEYSPACE IF EXISTS sparkify;'\n",
    "]\n",
    "for stmt in drop_stmt:\n",
    "    session.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}