{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, udf\n",
    "from pyspark.sql.types import IntegerType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(IntegerType())\n",
    "def get_date_part(date_delta, key):\n",
    "    date = datetime(year=1960, month=1, day=1) + timedelta(days=int(date_delta))\n",
    "    parts = {\n",
    "        \"day\": date.day,\n",
    "        \"weekday\": date.isoweekday(),\n",
    "        \"month\": date.month,\n",
    "        \"year\": date.year\n",
    "    }\n",
    "    return parts[key]\n",
    "\n",
    "df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "\n",
    "date_parts = [\"day\", \"weekday\", \"month\", \"year\"]\n",
    "for part in date_parts:\n",
    "    df = df.withColumn(part, get_date_part(\"arrdate\", lit(part)))\n",
    "\n",
    "df.createOrReplaceTempView(\"arrivals\")\n",
    "time_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT arrdate, day, weekday, month, year FROM arrivals\n",
    "\"\"\")\n",
    "time_table.write.partitionBy(\"year\", \"month\").mode(\"overwrite\").parquet(\"out/time.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "people_table = df.select(\n",
    "    df.admnum.cast(LongType()).alias(\"admission_number\"), \n",
    "    df.biryear.cast(IntegerType()).alias(\"birth_year\"), \n",
    "    df.gender, \n",
    "    df.i94addr.alias(\"address_state\")\n",
    ")\n",
    "people_table.write.partitionBy(\"gender\", \"birth_year\").mode(\"overwrite\").parquet(\"out/people.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visas_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT visatype AS type,\n",
    "    CASE\n",
    "        WHEN i94visa = 1.0 THEN 'business'\n",
    "        WHEN i94visa = 2.0 THEN 'leisure'\n",
    "        WHEN i94visa = 3.0 THEN 'student'\n",
    "    END AS purpose\n",
    "    FROM arrivals\n",
    "\"\"\")\n",
    "visas_table.write.mode(\"overwrite\").parquet(\"out/visas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrivals_table = df.select(\n",
    "    df.cicid.cast(LongType()).alias(\"id\"),\n",
    "    df.admnum.cast(LongType()).alias(\"person_id\"),\n",
    "    df.visatype.alias(\"visa\"),\n",
    "    df.i94res.cast(IntegerType()).alias(\"country_of_origin\"),\n",
    "    df.i94port.alias(\"port_of_entry\"),\n",
    "    df.arrdate.cast(LongType()).alias(\"date\"),\n",
    "    df.airline,\n",
    "    df.fltno.alias(\"flight_number\"),\n",
    "    df.dtaddto.alias(\"allowed_until_date\"),\n",
    "    df.visapost.alias(\"visa_issuer\")\n",
    ")\n",
    "arrivals_table.write.partitionBy(\"date\").mode(\"overwrite\").parquet(\"out/arrivals.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "US_STATES = (\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \n",
    "    \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \n",
    "    \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \n",
    "    \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    ")\n",
    "\n",
    "df_ports = spark.read.csv(\"data/i94_ports_all.csv\", header=True).dropna()\n",
    "df_ports.createOrReplaceTempView(\"ports_raw\")\n",
    "\n",
    "ports_of_entry_table = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT i94_port_code AS code, i94_port_name AS name, i94_port_state AS state \n",
    "    FROM ports_raw \n",
    "    WHERE i94_port_state IN {US_STATES}\n",
    "\"\"\")\n",
    "ports_of_entry_table.write.mode(\"overwrite\").parquet(\"out/ports_of_entry.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data/i94_countries_all.csv\", header=True).dropna()\n",
    "\n",
    "df = df.where(~(df.i94_country_name.startswith('No Country Code') | df.i94_country_name.startswith('Collapsed')))\n",
    "df = df.withColumn(\"country_code_as_int\", df.i94_country_code.cast(IntegerType()))\n",
    "remove_prefix_udf = udf(lambda value, prefix: value.replace(prefix, ''))\n",
    "df = df.withColumn(\"country_name_without_prefix\", remove_prefix_udf(\"i94_country_name\", lit(\"INVALID: \")))\n",
    "\n",
    "countries_table = df.select(df.country_code_as_int.alias(\"i94_code\"), df.country_name_without_prefix.alias(\"name\"))\n",
    "countries_table.write.mode(\"overwrite\").parquet(\"out/countries.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ports = spark.read.parquet(\"out/ports_of_entry.parquet\")\n",
    "print(ports.count())\n",
    "ports.where(ports.code == \"NYC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries = spark.read.parquet(\"out/countries.parquet\")\n",
    "print(countries.count())\n",
    "countries.where(countries.name == \"BRAZIL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrivals = spark.read.parquet(\"out/arrivals.parquet\")\n",
    "print(arrivals.count())\n",
    "arrivals.show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}